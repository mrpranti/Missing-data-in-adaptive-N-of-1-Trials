{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OMP_NUM_THREADS environment variable to 1 to avoid memory leak\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.535669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  patient_id  treatment   outcome\n",
       "0  0           0          0  0.125730\n",
       "1  1           0          0 -0.132105\n",
       "2  2           0          0  0.640423\n",
       "3  3           0          0  0.104900\n",
       "4  4           0          0 -0.535669"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/two_treatment/dt0_without_context.csv' ,index_col=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating random nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "column = 'outcome' ## clumn tht ill have missing value\n",
    "nan_fraction = 0.1  \n",
    "total_rows = len(df)\n",
    "nan_count = int(total_rows * nan_fraction)\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(0)\n",
    "nan_indices = np.random.choice(df.index, nan_count, replace=False)\n",
    "\n",
    "# Set those randomly selected positions to NaN in the specified column\n",
    "df.loc[nan_indices, column] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the dataframe to calculate missing data\n",
    "In a bayesian adaptive N_of_1 trials, we are going to calculate the missing data as we prepare to update the posterior joint distribution. Thus, the first step is to sepaate the dataframe when the first missing value appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.345584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.189053</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.040919</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.555665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.651791</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.174717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            c  t  patient_id  treatment   outcome\n",
       "0    0.125730  0           0          0 -0.132105\n",
       "30   0.345584  0           1          0       NaN\n",
       "60   0.189053  0           2          1 -0.522748\n",
       "90   2.040919  0           3          1 -2.555665\n",
       "120 -0.651791  0           4          0 -0.174717"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## seperating the dataframe at the point of first missing value\n",
    "nan_t = df[df.isna().any(axis=1)]['t']\n",
    "nan_t = nan_t.sort_values(ascending=True).unique() ## shorting the value in ascending order to make sure we dot the first time cycle\n",
    "ts = nan_t[0]\n",
    "dt = df[df['t'] <= ts].copy()\n",
    "dt.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have data set where we encountered the first missig value in the experiments. lets fill the missing value with various method.\n",
    "#### Context Clustering filling method\n",
    "For the context Clustering filling method, we are followin similar algorithm as Clustering to select suitable filling value. The context of the each patient and the treatment altogether is a vector $x_t$(i.e for patient id 1 the vector is $[c_1, c_2, ...., c_n, treatment]_{p_1}$). First, we cluster all $x_t$ in $N$ clusters with corresponding outcomes ($r$) , and claculate the each cluster's mean and centroids. Now, similar to KNN imputation method, we select $m$ nearest clusters' means. Finally, a weighted average of the clusters' means with distnce is taken to fill the missing value. the weighted average is as follows,\n",
    "\n",
    "\\begin{equation}\n",
    "        g(x_t) = \\frac{\\sum_{j=1}^{m}\\frac{\\bar{r_j}}{d_j}}{\\sum_{j=1}^{m}\\frac{1}{d_j}}\n",
    "\\end{equation}\n",
    "where $d_j$ represents the distance between $x_t$ and the centroid of $j^{th}$ cluster and $\\bar{r_j}$ (j th cluster mean) given by,\n",
    "\\begin{equation}\n",
    "\\tag{2}\n",
    "        \\bar{r_j} = \\frac{\\sum_{\\tau = 1}^{n_j} r_\\tau}{n_j}\n",
    "\\end{equation}\n",
    "\n",
    "If no context is available, then we are using the treatment as a singular context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(context_vectors, miss_vec):\n",
    "    \n",
    "    distances = []\n",
    "    for vector in context_vectors:\n",
    "        d = np.linalg.norm(vector - miss_vec)\n",
    "        distances.append(d) \n",
    "    return(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_fill(dt, context_cols = list, N = 2, m = 1): \n",
    "    # dt is the data Frame\n",
    "    # context_cols will be list of columns name which are considered as context \n",
    "    # N represents the number of clusters for KMean\n",
    "    \n",
    "    dt_fill = dt.copy()\n",
    "    miss_dt = dt_fill[dt_fill['outcome'].isna()]\n",
    "    without_miss_dt = dt_fill[dt_fill['outcome'].isna() == False].copy()\n",
    "    context_dt = without_miss_dt[context_cols]\n",
    "    \n",
    "    ## apply KMeans clustering to context_dt\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(context_dt)\n",
    "\n",
    "    kmeans = KMeans(n_clusters= N, random_state=0)  # Choose the number of clusters (2 in this case)\n",
    "    kmeans.fit(scaled_data)\n",
    "\n",
    "    without_miss_dt['cluster'] = kmeans.labels_  # Add cluster labels to the dataframe\n",
    "    centroids = kmeans.cluster_centers_  # Get cluster centroids\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for row in miss_dt.itertuples():\n",
    "        miss_vec = np.array([getattr(row, col) for col in context_cols])\n",
    "        \n",
    "        ## calculate the distance from the clustres cenroids\n",
    "        dis = get_distance(centroids, miss_vec)\n",
    "        dis_dt = pd.Series(dis)\n",
    "                \n",
    "        sorted_dis_dt = dis_dt.sort_values()\n",
    "        selected_cluster = sorted_dis_dt.index[:m].values ## to get m nearest clusters\n",
    "        \n",
    "        ## calculate the missing value with above mentioned equation (1)\n",
    "        clusters_mean = without_miss_dt.groupby('cluster')['outcome'].mean()\n",
    "        inverse_dis = 1 / dis_dt.loc[selected_cluster]\n",
    "        numerator = (clusters_mean.loc[selected_cluster] / dis_dt.loc[selected_cluster]).mean()\n",
    "        denominator = inverse_dis.mean()\n",
    "        \n",
    "        fill_value = numerator/denominator \n",
    "        \n",
    "        ## fill the missing value in appropiate place \n",
    "        dt_fill.loc[row.Index,'outcome'] = fill_value\n",
    "    \n",
    "    return dt_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**while t = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      86\n",
      "                                     True       14\n",
      "Name: count, dtype: int64\n",
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      100\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "m = 1\n",
    "context_cols = ['treatment']\n",
    "\n",
    "print(dt.isna().value_counts())\n",
    "filled_dt = context_fill(dt, context_cols, N, m)\n",
    "print(filled_dt.isna().value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**when t =! 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.345584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.200820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.330437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.303157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.189053</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>-0.425905</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.985005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>-1.087591</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.244621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>0.560527</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0.082494</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.464418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>0.050515</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             c  t  patient_id  treatment   outcome\n",
       "0     0.125730  0           0          0 -0.132105\n",
       "1     0.640423  1           0          0  0.104900\n",
       "30    0.345584  0           1          0 -0.200820\n",
       "31    0.330437  1           1          0 -1.303157\n",
       "60    0.189053  0           2          1 -0.522748\n",
       "...        ... ..         ...        ...       ...\n",
       "2911 -0.425905  1          97          0 -0.985005\n",
       "2940 -1.087591  0          98          0 -1.244621\n",
       "2941  0.560527  1          98          0       NaN\n",
       "2970  0.082494  0          99          1 -0.464418\n",
       "2971  0.050515  1          99          1  0.686231\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cycle = df[(df['t']> nan_t[0]) & (df['t'] <= nan_t[1])].copy()\n",
    "next_dt = pd.concat([filled_dt, next_cycle], axis= 0, ignore_index=False) # add the next cycle to the data\n",
    "next_dt = next_dt.sort_index()\n",
    "next_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      188\n",
      "                                     True        12\n",
      "Name: count, dtype: int64\n",
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      200\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(next_dt.isna().value_counts())\n",
    "next_filled_dt = context_fill(next_dt, context_cols, N, m)\n",
    "print(next_filled_dt.isna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.535669</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.703735</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.265421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          c  t  patient_id  treatment   outcome\n",
       "0  0.125730  0           0          0 -0.132105\n",
       "1  0.640423  1           0          0  0.104900\n",
       "2 -0.535669  2           0          0  0.361595\n",
       "3  1.304000  3           0          0  0.947081\n",
       "4 -0.703735  4           0          0 -1.265421"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('data/two_treatment/dt0_with_context.csv' ,index_col=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating random nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()\n",
    "column = 'outcome'\n",
    "nan_fraction = 0.1  \n",
    "\n",
    "total_rows = len(df)\n",
    "nan_count = int(total_rows * nan_fraction)\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(0)\n",
    "nan_indices = np.random.choice(df.index, nan_count, replace=False)\n",
    "\n",
    "# Set those randomly selected positions to NaN in the specified column\n",
    "df.loc[nan_indices, column] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the dataframe to calculate missing data\n",
    "In a bayesian aaptive N_of_1 trials, we are going to calculate the missing data as we prepare to update the posterior joint distribution. Thus, the first step is to sepaate the dataframe when the first missing value appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.345584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.189053</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.040919</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.555665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-0.651791</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.174717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            c  t  patient_id  treatment   outcome\n",
       "0    0.125730  0           0          0 -0.132105\n",
       "30   0.345584  0           1          0       NaN\n",
       "60   0.189053  0           2          1 -0.522748\n",
       "90   2.040919  0           3          1 -2.555665\n",
       "120 -0.651791  0           4          0 -0.174717"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## seperating the dataframe at the point of first missing value\n",
    "nan_t = df[df.isna().any(axis=1)]['t']\n",
    "nan_t = nan_t.sort_values(ascending=True).unique() ## shorting the value in ascending order to make sure we dot the first time cycle\n",
    "ts = nan_t[0]\n",
    "dt = df[df['t'] <= ts].copy()\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**while t = 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      86\n",
      "                                     True       14\n",
      "Name: count, dtype: int64\n",
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      100\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "m = 1\n",
    "context_cols = ['c', 'treatment']\n",
    "\n",
    "print(dt.isna().value_counts())\n",
    "filled_dt = context_fill(dt, context_cols, N, m)\n",
    "print(filled_dt.isna().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**while t != 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.345584</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.200820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.330437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.303157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.189053</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.522748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>-0.425905</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.985005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>-1.087591</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.244621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>0.560527</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0.082494</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.464418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>0.050515</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             c  t  patient_id  treatment   outcome\n",
       "0     0.125730  0           0          0 -0.132105\n",
       "1     0.640423  1           0          0  0.104900\n",
       "30    0.345584  0           1          0 -0.200820\n",
       "31    0.330437  1           1          0 -1.303157\n",
       "60    0.189053  0           2          1 -0.522748\n",
       "...        ... ..         ...        ...       ...\n",
       "2911 -0.425905  1          97          0 -0.985005\n",
       "2940 -1.087591  0          98          0 -1.244621\n",
       "2941  0.560527  1          98          0       NaN\n",
       "2970  0.082494  0          99          1 -0.464418\n",
       "2971  0.050515  1          99          1  0.686231\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_cycle = df[(df['t']> nan_t[0]) & (df['t'] <= nan_t[1])].copy()\n",
    "next_dt = pd.concat([filled_dt, next_cycle], axis= 0, ignore_index=False) # add the next cycle to the data\n",
    "next_dt = next_dt.sort_index()\n",
    "next_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      188\n",
      "                                     True        12\n",
      "Name: count, dtype: int64\n",
      "c      t      patient_id  treatment  outcome\n",
      "False  False  False       False      False      200\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(next_dt.isna().value_counts())\n",
    "next_filled_dt = context_fill(next_dt, context_cols, N, m)\n",
    "print(next_filled_dt.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
