{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.fromnumeric import mean\n",
    "#from adaptive_nof1.helpers import series_to_indexed_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import invgamma, norm\n",
    "import scipy\n",
    "import torch\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this note book we create a way to calculate the next treatment. It will help us to figure out if after filling the missing value, it selects the same treatment as in the original data frame. Here, the inference model for the thompson sampling is same as the adaptive_n_of_1 we used for the data simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.535669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  patient_id  treatment   outcome\n",
       "0  0           0          0  0.125730\n",
       "1  1           0          0 -0.132105\n",
       "2  2           0          0  0.640423\n",
       "3  3           0          0  0.104900\n",
       "4  4           0          0 -0.535669"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/two_treatment/dt0_without_context.csv' ,index_col=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating random nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()\n",
    "column = 'outcome'\n",
    "nan_fraction = 0.1  # 30% of the data in column B will be set to NaN\n",
    "\n",
    "total_rows = len(df)\n",
    "nan_count = int(total_rows * nan_fraction)\n",
    "\n",
    "# seed for reproducibility\n",
    "np.random.seed(0)\n",
    "nan_indices = np.random.choice(df.index, nan_count, replace=False)\n",
    "\n",
    "# Set those randomly selected positions to NaN in the specified column\n",
    "df.loc[nan_indices, column] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.040919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.651791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t  patient_id  treatment   outcome\n",
       "0    0           0          0  0.125730\n",
       "30   0           1          0       NaN\n",
       "60   0           2          0  0.189053\n",
       "90   0           3          0  2.040919\n",
       "120  0           4          0 -0.651791"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## seperating the dataframe at the point of first missing value\n",
    "nan_t = df[df.isna().any(axis=1)]['t']\n",
    "nan_t = nan_t.sort_values(ascending=True).unique() ## shorting the value in ascending order to make sure we dot the first time cycle\n",
    "ts = nan_t[0]\n",
    "dt = df[df['t'] <= ts].copy()\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThompsonSampling():\n",
    "    def __init__(\n",
    "        self,\n",
    "        inference_model,\n",
    "        number_of_treatments,\n",
    "        posterior_update_interval=1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.inference = inference_model\n",
    "        self.posterior_update_interval = posterior_update_interval\n",
    "        self.number_of_treatments = number_of_treatments\n",
    "        self._debug_data = []\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def additional_config(self):\n",
    "        return {\"inference\": f\"{self.inference}\"}\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"ThompsonSampling({self.inference})\"\n",
    "\n",
    "    def choose_action(self, history, context):\n",
    "        if (\n",
    "            len(history) % self.posterior_update_interval == 0\n",
    "            or self.inference.trace is None\n",
    "        ):\n",
    "            self.inference.update_posterior(history, self.number_of_treatments)\n",
    "\n",
    "        probability_array = self.inference.approximate_max_probabilities(\n",
    "            self.number_of_treatments, context\n",
    "        )\n",
    "        action = random.choices(\n",
    "            range(self.number_of_treatments), weights=probability_array\n",
    "        )[0]\n",
    "       ## self._debug_information += [\n",
    "        #    f\"Probabilities for picking: {numpy.array_str(numpy.array(probability_array), precision=2, suppress_small=True)}, chose {action}\"\n",
    "       # ]\n",
    "       # debug_data_from_model = self.inference.debug_data\n",
    "        #self._debug_data.append(\n",
    "         #   {**{\"probabilities\": probability_array}, **debug_data_from_model}\n",
    "        #)\n",
    "        return action\n",
    "    \n",
    "    @property\n",
    "    def debug_data(self):\n",
    "        return self._debug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference model for the thompson sampling\n",
    "\n",
    "class NormalKnownVariance:\n",
    "    def __init__(\n",
    "        self,\n",
    "        treatment_name=\"treatment\",\n",
    "        outcome_name=\"outcome\",\n",
    "        prior_mean=0,\n",
    "        prior_variance=1,\n",
    "        variance=1,\n",
    "        seed=None,\n",
    "    ):\n",
    "        assert variance > 0, \"Variance must be positive\"\n",
    "        self.treatment_name = treatment_name\n",
    "        self.outcome_name = outcome_name\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.prior_mean = prior_mean\n",
    "        self.prior_variance = prior_variance\n",
    "        self.variance = variance\n",
    "        self.number_of_interventions = None\n",
    "\n",
    "        self.df = None\n",
    "        self._debug_data = {\"mean\": prior_mean, \"variance\": prior_variance}\n",
    "\n",
    "    # This is an upper bound for the mean effect.\n",
    "    # One could also upper bound the reward, which would add additional variance from self.variance.\n",
    "    # For selection in UCB, this is irrelevant, since the max is chosen anyway.\n",
    "    def get_upper_confidence_bounds(self, variable_name, epsilon: float = 0.05):\n",
    "        assert variable_name == self.outcome_name, \"Only outcome variable supported\"\n",
    "        assert (\n",
    "            self.number_of_interventions is not None\n",
    "        ), \"Do not call get_upper_confidence_bounds without previously calling update_posterior\"\n",
    "        mean, variance = self.posterior_parameters(self.number_of_interventions)\n",
    "        upper_confidence_bounds = norm.ppf(\n",
    "            1 - epsilon,\n",
    "            loc=mean,\n",
    "            scale=np.sqrt(np.array(variance)),\n",
    "        )\n",
    "        return upper_confidence_bounds\n",
    "\n",
    "    def update_posterior(self, history, number_of_treatments): ## history can be changed into the df\n",
    "        self.number_of_interventions = number_of_treatments\n",
    "        #self.history = history\n",
    "        self.df = history\n",
    "        mean, variance = self.posterior_parameters(number_of_treatments)\n",
    "        self._debug_data = {\"mean\": mean, \"variance\": variance}\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"NormalKnownVariance({self.prior_mean}, {self.prior_variance}, {self.variance})\"\n",
    "\n",
    "    def n(self, intervention):\n",
    "        return len(self.series(intervention)) # number of arm played in the history \n",
    "\n",
    "    def series(self, intervention):\n",
    "        return self.df[self.df[self.treatment_name] == intervention][self.outcome_name] ## getting the outcome variable\n",
    "\n",
    "    def var(self, intervention):\n",
    "        var = np.var(self.series(intervention))\n",
    "        return var\n",
    "\n",
    "    def sum(self, intervention):\n",
    "        return np.sum(self.series(intervention))\n",
    "\n",
    "    def mean_update(self, intervention):\n",
    "        return self.variance_update(intervention) * (\n",
    "            self.prior_mean / self.prior_variance\n",
    "            + (self.sum(intervention) / self.variance)\n",
    "        )\n",
    "\n",
    "    def variance_update(self, intervention):\n",
    "        return 1.0 / (\n",
    "            (1.0 / self.prior_variance) + self.n(intervention) / self.variance\n",
    "        )\n",
    "\n",
    "    def sample_posterior_predictive(\n",
    "        self, mean, variance, sample_size, number_of_treatments\n",
    "    ):\n",
    "        # Sample from our updated distributions\n",
    "        samples = norm.rvs(\n",
    "            loc=mean,\n",
    "            scale=np.sqrt(np.array(variance) + self.variance),\n",
    "            size=(sample_size, number_of_treatments),\n",
    "        )\n",
    "        return samples\n",
    "\n",
    "    def multivariate_normal_distribution(self):\n",
    "        mean = self._debug_data[\"mean\"]\n",
    "        variance = self._debug_data[\"variance\"]\n",
    "        cov = torch.diag_embed(torch.tensor(np.sqrt(variance)))\n",
    "        return torch.distributions.MultivariateNormal(torch.tensor(mean), cov)\n",
    "\n",
    "    def posterior_parameters(self, number_of_treatments):\n",
    "        mean = []\n",
    "        variance = []\n",
    "\n",
    "        for intervention in range(number_of_treatments):\n",
    "            mean.append(self.mean_update(intervention))\n",
    "            variance.append(self.variance_update(intervention))\n",
    "\n",
    "        return mean, variance\n",
    "\n",
    "    def sample_posterior_means(self, mean, variance, sample_size, number_of_treatments):\n",
    "        samples = norm.rvs(\n",
    "            loc=mean,\n",
    "            scale=np.sqrt(np.array(variance)),\n",
    "            size=(sample_size, number_of_treatments),\n",
    "        )\n",
    "        return samples\n",
    "\n",
    "    # This calculates the probability from our model that each treatment is the best by sampling from the mean values\n",
    "    def approximate_max_probabilities(self, number_of_treatments, context):\n",
    "        # calculate posterior parameters:\n",
    "        # See https://en.wikipedia.org/wiki/Conjugate_prior and then Normal with known variance\n",
    "\n",
    "        mean, variance = self.posterior_parameters(number_of_treatments)\n",
    "        self._debug_data = {\"mean\": mean, \"variance\": variance}\n",
    "\n",
    "        sample_size = 5000\n",
    "        samples = self.sample_posterior_means(\n",
    "            mean, variance, sample_size, number_of_treatments\n",
    "        )\n",
    "\n",
    "        max_indices = np.argmax(samples, axis=1)\n",
    "\n",
    "        bin_counts = np.bincount(max_indices, minlength=number_of_treatments)\n",
    "        return bin_counts / np.sum(bin_counts)\n",
    "\n",
    "    @property\n",
    "    def debug_data(self):\n",
    "        return self._debug_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making simulation for the next action choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miss_fill import context_fill, mean_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_vectors(without_miss_dt, context_cols):\n",
    "        \n",
    "    context_vectors = []\n",
    "    for row in without_miss_dt.itertuples():\n",
    "        row_values = [getattr(row, col) for col in context_cols]\n",
    "        context_vectors.append(row_values)\n",
    "\n",
    "    return (np.array(context_vectors))\n",
    "\n",
    "def get_distance(context_vectors, miss_vec):\n",
    "    \n",
    "    distances = []\n",
    "    for vector in context_vectors:\n",
    "        d = np.linalg.norm(vector - miss_vec)\n",
    "        distances.append(d) \n",
    "    return(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_fill(dt, context_cols = list, k = 1): \n",
    "    # dt is the data Frame\n",
    "    # context_cols will be list of columns name which are considered as context \n",
    "    \n",
    "    dt_fill = dt.copy()\n",
    "    miss_dt = dt_fill[dt_fill['outcome'].isna()]\n",
    "    without_miss_dt = dt_fill[dt_fill['outcome'].isna() == False].copy()\n",
    "    context_vectors = get_context_vectors(without_miss_dt, context_cols)\n",
    "    \n",
    "    for row in miss_dt.itertuples():\n",
    "        miss_vec = np.array([getattr(row, col) for col in context_cols])\n",
    "        dis = get_distance(context_vectors, miss_vec)\n",
    "        without_miss_dt['distance'] = dis\n",
    "        \n",
    "        sorted_without_miss_dt = without_miss_dt.sort_values(by = 'distance')\n",
    "        \n",
    "        fill_value = sorted_without_miss_dt['outcome'].head(k).mean()\n",
    "        dt_fill.loc[row.Index,'outcome'] = fill_value\n",
    "    \n",
    "    return dt_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.040919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.651791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.087591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t  patient_id  treatment   outcome\n",
       "0     0           0          0  0.125730\n",
       "30    0           1          0       NaN\n",
       "60    0           2          0  0.189053\n",
       "90    0           3          0  2.040919\n",
       "120   0           4          0 -0.651791\n",
       "...  ..         ...        ...       ...\n",
       "2850  0          95          1       NaN\n",
       "2880  0          96          1 -0.907213\n",
       "2910  0          97          1       NaN\n",
       "2940  0          98          0 -1.087591\n",
       "2970  0          99          0  0.082494\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "dt_fill = dt.copy()\n",
    "dt_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t      patient_id  treatment  outcome\n",
      "False  False       False      False      86\n",
      "                              True       14\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m context_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dt\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m----> 5\u001b[0m filled_dt \u001b[38;5;241m=\u001b[39m context_fill\u001b[38;5;241m.\u001b[39mContextFill\u001b[38;5;241m.\u001b[39mKNN_fill(dt, context_cols, k)\n",
      "File \u001b[1;32mc:\\Users\\USER1\\OneDrive\\Documents\\Thesis\\Wriiting and code\\miss_fill\\context_fill.py:44\u001b[0m, in \u001b[0;36mContextFill.KNN_fill\u001b[1;34m(self, dt, context_cols, k)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mKNN_fill\u001b[39m(\u001b[38;5;28mself\u001b[39m, dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame, context_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m): \n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# dt is the data Frame\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# context_cols will be list of columns name which are considered as context \u001b[39;00m\n\u001b[0;32m     43\u001b[0m     dt_fill \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 44\u001b[0m     miss_dt \u001b[38;5;241m=\u001b[39m dt_fill[dt_fill[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\n\u001b[0;32m     45\u001b[0m     without_miss_dt \u001b[38;5;241m=\u001b[39m dt_fill[dt_fill[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     46\u001b[0m     context_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_context_vectors(without_miss_dt, context_cols)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "context_cols = ['treatment', 'patient_id']\n",
    "\n",
    "print(dt.isna().value_counts())\n",
    "filled_dt = context_fill.ContextFill.KNN_fill(dt, context_cols, k)\n",
    "# print(filled_dt.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['treatment', 'patient_id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = filled_dt[['t', 'patient_id']].copy()\n",
    "history = filled_dt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Model\n",
    "inference_model = NormalKnownVariance(\n",
    "    \n",
    "    prior_mean=0, prior_variance=1, variance=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmps = ThompsonSampling(inference_model, number_of_treatments=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 100\n",
    "\n",
    "action = []\n",
    "for i in range(0, n_sim):\n",
    "    a = tmps.choose_action(history, context)\n",
    "    action.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    61\n",
      "0    39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_count = pd.Series(action).value_counts()\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
