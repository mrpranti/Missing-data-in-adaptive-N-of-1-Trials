\begin{thebibliography}{1}

\bibitem{Bouneffouf2020}
Djallel Bouneffouf, Sohini Upadhyay, and Yasaman Khazaeni.
\newblock Contextual bandit with missing rewards.
\newblock {\em arXiv preprint arXiv:2007.06368}, 7 2020.

\bibitem{Chen2022}
Xijin Chen, Kim~May Lee, Sofia~S. Villar, and David~S. Robertson.
\newblock Some performance considerations when using multi-armed bandit
  algorithms in the presence of missing data.
\newblock {\em PLoS ONE}, 17, 9 2022.
\newblock Method: using a simple mean imputation approach.

\bibitem{Kim}
Wonyoung Kim, Gi-Soo Kim, and Myunghee~Cho Paik.
\newblock Doubly robust thompson sampling with linear payoffs.
\newblock While Kim and Paik [2019] uses Lasso estimator with pseudo-rewards
  aggregated over allarms, we use ridge regression estimator with
  pseudo-rewards in (1) which are deÔ¨Åned separately foreach i = 1, . . . ,N.

\bibitem{Senarathne2020}
Siththara Gedara~J. Senarathne, Antony~M. Overstall, and James~M. McGree.
\newblock Bayesian adaptive n-of-1 trials for estimating population and
  individual treatment effects.
\newblock {\em Statistics in Medicine}, 39:4499--4518, 12 2020.

\bibitem{Wei1990}
Greg C.~G. Wei and Martin~A. Tanner.
\newblock A monte carlo implementation of the em algorithm and the poor man's
  data augmentation algorithms.
\newblock {\em Journal of the American Statistical Association}, 85:699--704, 9
  1990.

\bibitem{Yamaguchi2020}
Nobuhiko Yamaguchi, Osamu Fukuda, and Hiroshi Okumura.
\newblock Model-based reinforcement learning with missing data.
\newblock In {\em Proceedings - 2020 8th International Symposium on Computing
  and Networking Workshops, CANDARW 2020}, pages 168--171. Institute of
  Electrical and Electronics Engineers Inc., 11 2020.

\end{thebibliography}
